{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab9709f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: [情報] 淘寶使用心得~~ :)\n",
      "Author: smi1e\n",
      "Date: 10/22\n",
      "\n",
      "\n",
      "Title: [情報] 淘寶使用心得與說明\n",
      "Author: myday7582\n",
      "Date:  1/16\n",
      "\n",
      "\n",
      "Title: [心得] 使用過的淘寶賣家--寵物篇\n",
      "Author: altoids\n",
      "Date:  4/30\n",
      "\n",
      "\n",
      "Title: [問題] 請問有沒有人買淘寶，被海關抽稅?\n",
      "Author: kkjun72\n",
      "Date:  5/26\n",
      "\n",
      "\n",
      "Title: [心得] 超簡單!!自己充值支付寶(淘寶 淘1站)\n",
      "Author: besimplegirl\n",
      "Date:  9/09\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# 设置PTT电子商务版的URL模板\n",
    "url_template = 'https://www.ptt.cc/bbs/e-shopping/index{}.html'\n",
    "\n",
    "# 构建一个Session对象以处理PTT的年龄认证\n",
    "session = requests.Session()\n",
    "payload = {'from': url_template.format(''), 'yes': 'yes'}\n",
    "session.post('https://www.ptt.cc/ask/over18', data=payload)\n",
    "\n",
    "# 关键词\n",
    "keyword = \"淘寶\"\n",
    "\n",
    "# 创建一个空的列表用于存储匹配的帖子\n",
    "matched_posts = []\n",
    "\n",
    "# 循环遍历前10页内容\n",
    "for page in range(1, 11):\n",
    "    url = url_template.format(page)\n",
    "    \n",
    "    # 发送GET请求并获取页面内容\n",
    "    response = session.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # 使用Beautiful Soup解析页面内容\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 找到帖子的元素，通常它们有一个特定的class\n",
    "        posts = soup.find_all(class_='r-ent')\n",
    "\n",
    "        # 遍历帖子元素并提取信息\n",
    "        for post in posts:\n",
    "            title = post.find(class_='title').text.strip()\n",
    "            \n",
    "            # 检查帖子标题中是否包含关键词\n",
    "            if keyword in title:\n",
    "                author = post.find(class_='author').text\n",
    "                date = post.find(class_='date').text\n",
    "                print(f'Title: {title}')\n",
    "                print(f'Author: {author}')\n",
    "                print(f'Date: {date}')\n",
    "                print('\\n')\n",
    "\n",
    "    else:\n",
    "        print(f'Failed to retrieve page {page}. Status code:', response.status_code)\n",
    "        \n",
    "# 将匹配的帖子数据保存为CSV文件\n",
    "with open('matched_posts.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Title', 'Author', 'Date']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(matched_posts)\n",
    "\n",
    "# 将匹配的帖子数据保存为JSON文件\n",
    "with open('matched_posts.json', 'w') as jsonfile:\n",
    "    json.dump(matched_posts, jsonfile, ensure_ascii=False, indent=4)\n",
    "    \n",
    "import csv\n",
    "\n",
    "# 读取CSV文件\n",
    "with open('matched_posts.csv', 'r', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        \n",
    "import json\n",
    "\n",
    "# 读取JSON文件\n",
    "with open('matched_posts.json', 'r', encoding='utf-8') as jsonfile:\n",
    "    data = json.load(jsonfile)\n",
    "    for item in data:\n",
    "        print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75042702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
